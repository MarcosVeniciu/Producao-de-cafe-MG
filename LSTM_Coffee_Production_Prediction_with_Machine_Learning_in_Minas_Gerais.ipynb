{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarcosVeniciu/Producao-de-cafe-MG/blob/main/LSTM_Coffee_Production_Prediction_with_Machine_Learning_in_Minas_Gerais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpfp55EzbMPS"
      },
      "outputs": [],
      "source": [
        "# requeriment\n",
        "#%capture\n",
        "!pip cache purge\n",
        "!mkdir -p ~/tmp_pip\n",
        "!TMPDIR=~/tmp_pip pip install --no-cache-dir neuralforecast statsforecast optuna plotly scikit-learn lightning ipywidgets openpyxl nbformat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FXKQua4bjZ-"
      },
      "source": [
        "# Funções de suporte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "i0RDBFRodewu"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score, root_mean_squared_error\n",
        "from neuralforecast.losses.pytorch import HuberLoss\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from torch.optim.lr_scheduler import CyclicLR\n",
        "from neuralforecast import NeuralForecast\n",
        "from IPython.display import clear_output\n",
        "from neuralforecast.models import LSTM\n",
        "import plotly.graph_objects as go\n",
        "from datetime import datetime\n",
        "from torch.optim import AdamW\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import optuna\n",
        "import shutil\n",
        "import math\n",
        "import time\n",
        "import glob\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "V5c-Ty2TbnBN"
      },
      "outputs": [],
      "source": [
        "def train_model(\n",
        "    train_df,\n",
        "    test_df,\n",
        "    exog_list,\n",
        "    h: int,\n",
        "    input_size: int,\n",
        "    output_dir: str = './model',\n",
        "    steps: int = 500,\n",
        "    default_params: dict = None,\n",
        "    n_trials: int = 20,\n",
        "    val_df=None,\n",
        "    freqencia: str = \"YE\"  # Frequência dos dados, por exemplo, \"YE\" para Final do ano, ME para Final do mês, etc.\n",
        "):\n",
        "    \"\"\"\n",
        "    Treina um modelo LSTM usando os parâmetros em default_params.\n",
        "    - Se default_params for um dict, executa o treinamento com esses parâmetros.\n",
        "    - Se default_params for None, exibe um aviso e não prossegue com o treinamento.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Verifica se os parâmetros foram fornecidos\n",
        "    if default_params is None:\n",
        "        print(\"Você deve informar os parametros a serem usados no treinamento!\")\n",
        "        return None\n",
        "\n",
        "    # Branch sem Optuna: usa os parâmetros fornecidos\n",
        "    model = LSTM(\n",
        "        h=h,\n",
        "        input_size=input_size,\n",
        "        **default_params\n",
        "    )\n",
        "    nf = NeuralForecast(models=[model], freq=freqencia)\n",
        "    nf.fit(df=train_df)\n",
        "    nf.save(path=output_dir, overwrite=True, save_dataset=False)\n",
        "\n",
        "    # Empacota os artefatos em um ZIP\n",
        "    zip_path = Path(output_dir) / \"model_bundle.zip\"\n",
        "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
        "        for root, _, files in os.walk(output_dir):\n",
        "            for f in files:\n",
        "                if f != zip_path.name:\n",
        "                    zf.write(os.path.join(root, f), arcname=f)\n",
        "    print(f\"\\nModel artifacts zipped to {zip_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "vOuheeIUjQgz"
      },
      "outputs": [],
      "source": [
        "def rolling_evaluation(model, full_df: pd.DataFrame, test_df: pd.DataFrame, context_size: int, horizon: int, inteiro=True) -> pd.DataFrame:\n",
        "  # --- Preparação inicial ---\n",
        "  # Garantir que as datas estejam em datetime e ordenar os dataframes\n",
        "  full_df = full_df.copy()\n",
        "  test_df = test_df.copy()\n",
        "  full_df['ds'] = pd.to_datetime(full_df['ds'])\n",
        "  test_df['ds'] = pd.to_datetime(test_df['ds'])\n",
        "\n",
        "  # Todos os valores exclusivos de datas no período de teste, ordenados\n",
        "  test_dates = sorted(test_df['ds'].unique())\n",
        "  # Determina quantas janelas de previsão iremos executar\n",
        "  n_dates = len(test_dates)\n",
        "  n_loops = math.ceil(n_dates / horizon)\n",
        "\n",
        "  all_forecasts = []\n",
        "\n",
        "  # --- Loop de previsão por janelas de tamanho `horizon` ---\n",
        "  for j in range(n_loops):\n",
        "      # Identifica o bloco de datas que compõem o horizonte atual\n",
        "      date_chunk = test_dates[j * horizon : (j + 1) * horizon]\n",
        "      start_date = date_chunk[0]  # Data de início dessa janela de previsão\n",
        "\n",
        "      print(f\"\\nExecutando window {j+1}/{n_loops}: datas {date_chunk[0].date()} a {date_chunk[-1].date()}\")\n",
        "      val_df = test_df[test_df['ds'].isin(date_chunk)] # possui os dados de teste para a janela atual\n",
        "      history_df = full_df[full_df['ds'] < start_date] # possui os dados historicos para a janela atual\n",
        "      futr_df = val_df.drop(columns=[\"y\"]).copy()\n",
        "\n",
        "      # Realiza a predição para a janela atual\n",
        "      forecasts_df = model.predict(\n",
        "        df=history_df,         # Dados históricos (para contexto)\n",
        "        futr_df=futr_df      # Valores futuros das variáveis exógenas\n",
        "      )\n",
        "      # Combinar previsões com valores reais do teste\n",
        "      evaluation_df = forecasts_df.merge(\n",
        "          val_df[[\"unique_id\", \"ds\", \"y\"]],\n",
        "          on=[\"unique_id\", \"ds\"]\n",
        "      )\n",
        "      evaluation_df['y'] = np.expm1(evaluation_df['y']) # Inverte a transformação log1p aplicada nos dados\n",
        "      evaluation_df['LSTM'] = np.expm1(evaluation_df['LSTM']) # Inverte a transformação log1p aplicada nas previsões\n",
        "\n",
        "      if inteiro:\n",
        "        evaluation_df['LSTM'] = evaluation_df['LSTM'].round().astype(int)\n",
        "        evaluation_df['y'] = evaluation_df['y'].round().astype(int)\n",
        "\n",
        "      all_forecasts.append(evaluation_df)\n",
        "\n",
        "  # --- Concatena todas as previsões obtidas ---\n",
        "  forecasts_df = pd.concat(all_forecasts, ignore_index=True)\n",
        "  forecasts_df = calcular_diferenca_percentual(forecasts_df)\n",
        "\n",
        "  return forecasts_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "qJABAATFzm1s"
      },
      "outputs": [],
      "source": [
        "def generate_steps_options():\n",
        "  # Intervalos com granularidade fina no início\n",
        "  step_1 = list(range(500, 1001, 100))\n",
        "  step_2 = list(range(1100, 2001, 200))\n",
        "  step_3 = list(range(2200, 5001, 400))\n",
        "\n",
        "  steps_options = step_1 + step_2 + step_3\n",
        "  return sorted(steps_options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "6M4jIJoHhHR3"
      },
      "outputs": [],
      "source": [
        "## WMAPE (Weighted MAPE)\n",
        "def wmape(actual, predicted):\n",
        "  return np.sum(np.abs(predicted - actual)) / np.sum(np.abs(actual))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calcula_diferenca_pct(row):\n",
        "    if row['y_pred'] == \"-\" or row['y_pred'] is None:\n",
        "        return \"-\"\n",
        "    try:\n",
        "        y_pred_float = float(row['y_pred'])\n",
        "        y_real = float(row['y'])\n",
        "        # Evita divisão por zero\n",
        "        if y_real == 0:\n",
        "            return \"-\"\n",
        "        # Calcula diferença percentual absoluta\n",
        "        diff_pct = abs((y_pred_float - y_real) / y_real) * 100\n",
        "        return round(diff_pct, 2)\n",
        "    except:\n",
        "        return \"-\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "rVBwOZJSjM42"
      },
      "outputs": [],
      "source": [
        "def calcular_diferenca_percentual(df):\n",
        "    \"\"\"\n",
        "    Calcula a diferença percentual entre valores preditos (LSTM) e reais (y)\n",
        "    e retorna um novo DataFrame com a coluna adicional 'diferença_%'\n",
        "\n",
        "    Fórmula: ((LSTM - y) / y) * 100\n",
        "\n",
        "    Interpretação:\n",
        "    - Valor negativo: previsão subestimada (LSTM < y)\n",
        "    - Valor positivo: previsão superestimada (LSTM > y)\n",
        "\n",
        "    Parâmetros:\n",
        "    df (DataFrame): DataFrame com colunas 'y' e 'LSTM'\n",
        "\n",
        "    Retorna:\n",
        "    DataFrame: Novo DataFrame com a coluna 'diferença_%' adicionada\n",
        "    \"\"\"\n",
        "    # Cria uma cópia do DataFrame para não modificar o original\n",
        "    df_novo = df.copy()\n",
        "\n",
        "    # Calcula a diferença percentual com sinal correto\n",
        "    df_novo['diferença_%'] = round(((df_novo['LSTM'] - df_novo['y']) / df_novo['y']) * 100, 2)\n",
        "\n",
        "    return df_novo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import os\n",
        "\n",
        "def plot_losses(csv_path): \n",
        "    # Carrega o DataFrame\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Cria a figura\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Plot Train Loss por época (filtra NaN)\n",
        "    if \"train_loss_epoch\" in df.columns:\n",
        "        mask = df[\"train_loss_epoch\"].notna()\n",
        "        if mask.any():\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=df.loc[mask, \"epoch\"],\n",
        "                y=df.loc[mask, \"train_loss_epoch\"],\n",
        "                mode='lines+markers',\n",
        "                name='Train Loss (Epoch)',\n",
        "                line=dict(color='blue')\n",
        "            ))\n",
        "        else:\n",
        "            print(\"Sem dados na coluna 'train_loss_epoch'.\")\n",
        "    else:\n",
        "        print(\"Atenção: coluna 'train_loss_epoch' não encontrada. Pulando plot de treino.\")\n",
        "\n",
        "    # Plot Valid Loss (filtra NaN)\n",
        "    if \"valid_loss\" in df.columns:\n",
        "        mask = df[\"valid_loss\"].notna()\n",
        "        if mask.any():\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=df.loc[mask, \"epoch\"],\n",
        "                y=df.loc[mask, \"valid_loss\"],\n",
        "                mode='lines+markers',\n",
        "                name='Valid Loss',\n",
        "                line=dict(color='orange')\n",
        "            ))\n",
        "        else:\n",
        "            print(\"Sem dados na coluna 'valid_loss'.\")\n",
        "    else:\n",
        "        print(\"Atenção: coluna 'valid_loss' não encontrada. Pulando plot de validação.\")\n",
        "\n",
        "    # Checa se tem dados\n",
        "    if not fig.data:\n",
        "        print(\"Nenhuma curva disponível para plotar.\")\n",
        "        return\n",
        "\n",
        "    # Layout do gráfico\n",
        "    fig.update_layout(\n",
        "        title=\"Loss por Época\",\n",
        "        xaxis_title=\"Época\",\n",
        "        yaxis_title=\"Loss\",\n",
        "        legend=dict(x=0.01, y=0.99),\n",
        "        template=\"plotly_white\"\n",
        "    )\n",
        "\n",
        "    # Mostra o gráfico\n",
        "    fig.show()\n",
        "\n",
        "    # Salva o gráfico na mesma pasta do CSV\n",
        "    output_folder = os.path.dirname(csv_path)\n",
        "    output_path = os.path.join(output_folder, \"grafico_loss.html\")\n",
        "\n",
        "    fig.write_html(output_path)\n",
        "    print(f\"Gráfico salvo em: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N5MPG0Eb1_1"
      },
      "source": [
        "# Preparar dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "UxBTGb6fb3rx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de dados: 244\n"
          ]
        }
      ],
      "source": [
        "dataset = pd.read_csv('Dataset/V0/dataset_v0.csv')\n",
        "print(f\"Total de dados: {len(dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SWezrzodjf9"
      },
      "outputs": [],
      "source": [
        "# Definindo as colunas categóricas\n",
        "cat_features = ['Mesorregião', \"Municipio\"]\n",
        "\n",
        "# Gerando a lista de colunas numéricas (todas as colunas exceto as categóricas)\n",
        "num_features = [col for col in dataset.columns if col not in cat_features]\n",
        "\n",
        "# Seleciona as colunas\n",
        "dataset = dataset[num_features + cat_features].copy()\n",
        "# Formatando a saída conforme solicitado\n",
        "print(\"Num Features:\")\n",
        "for feature in num_features:\n",
        "    print(f\"    - {feature}\")\n",
        "\n",
        "print(\"\\nCat Features:\")\n",
        "for feature in cat_features:\n",
        "    print(f\"    - {feature}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wnkORhdA6JZ"
      },
      "source": [
        "- Log-transform em Área colhida, Quantidade (em mil toneladas) e Valor da produção."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# copie a série original antes de qualquer transformação\n",
        "original = dataset['target'].copy()\n",
        "# aplique log1p no original\n",
        "transformed = np.log1p(original)\n",
        "\n",
        "# monta o gráfico\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# distribuição original\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(original, kde=True, bins=30)\n",
        "plt.title('Original – target')\n",
        "plt.xlabel('target')\n",
        "plt.ylabel('Frequência')\n",
        "\n",
        "# distribuição log1p\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(transformed, kde=True, bins=30)\n",
        "plt.title('Log1p Transformado – target')\n",
        "plt.xlabel('log1p(target)')\n",
        "plt.ylabel('Frequência')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ac-qLbE_A6JZ"
      },
      "outputs": [],
      "source": [
        "log_cols = [\n",
        "  'Área colhida (Hectares)',\n",
        "  'target',\n",
        "  'Valor da produção (Mil Reais)'\n",
        "]\n",
        "\n",
        "# Verifica quais colunas de log_cols estão presentes no dataset\n",
        "existing_log_cols = [col for col in log_cols if col in dataset.columns]\n",
        "\n",
        "# Mostra as colunas que serão transformadas\n",
        "print(\"Colunas encontradas para aplicar log1p:\", existing_log_cols)\n",
        "\n",
        "# Aplica log1p apenas nas colunas presentes\n",
        "dataset[existing_log_cols] = dataset[existing_log_cols].apply(lambda x: np.log1p(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuRPRmNpUHwn"
      },
      "outputs": [],
      "source": [
        "# Renomeando as colunas para o formato esperado pelo NeuralForecast\n",
        "dataset = dataset.rename(columns={\n",
        "  \"Municipio_id\": \"unique_id\",\n",
        "  \"Ano\": \"ds\",\n",
        "  \"target\": \"y\"\n",
        "})\n",
        "dataset = dataset.sort_values(by=[\"unique_id\", \"ds\"]).reset_index(drop=True)\n",
        "# Converte o ano inteiro para uma string no formato 'YYYY-12-31' (último dia do ano)\n",
        "dataset['ds'] = pd.to_datetime(dataset['ds'].astype(str) + '-12-31')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-__DowYalJi"
      },
      "outputs": [],
      "source": [
        "# Inicializa o OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# Lista de colunas categóricas para codificar\n",
        "colunas_categoricas = [\"Mesorregião\", \"Municipio\"]\n",
        "\n",
        "# Aplica o encoder nas colunas selecionadas\n",
        "encoded_data = encoder.fit_transform(dataset[colunas_categoricas])\n",
        "\n",
        "# Cria um DataFrame com os nomes das colunas codificadas\n",
        "encoded_df = pd.DataFrame(\n",
        "    encoded_data,\n",
        "    columns=encoder.get_feature_names_out(colunas_categoricas),\n",
        "    index=dataset.index  # Mantém o mesmo índice\n",
        ")\n",
        "\n",
        "# Concatena o DataFrame codificado com o dataset original\n",
        "dataset = pd.concat([dataset.drop(columns=colunas_categoricas), encoded_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Use-o caso queira treinar sem o uso das variaveis exogenas!\n",
        "#dataset= dataset[[\"ds\", \"y\", \"unique_id\"]].copy()\n",
        "#dataset.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObvNIuwHjtoV"
      },
      "outputs": [],
      "source": [
        "exog_list = [col for col in dataset.columns.tolist() if col not in [\"ds\", \"y\", \"unique_id\"]]\n",
        "print(f\"Variaveis Exogenas:\")\n",
        "for col in exog_list:\n",
        "  print(f\" - {col}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tabela de treinamentos:\n",
        "\n",
        "| Treino       | Validação | Teste |\n",
        "|--------------|-----------|-------|\n",
        "| 2012-2015    | 2016      | 2017  |\n",
        "| 2012-2016    | 2017      | 2018  |\n",
        "| 2012-2017    | 2018      | 2019  |\n",
        "| 2012-2018    | 2019      | 2020  |\n",
        "| 2012-2019    | 2020      | 2021  |\n",
        "| 2012-2020    | 2021      | 2022  |\n",
        "| 2012-2021    | 2022      | 2023  |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "MOa5Cwmfd709"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dados de Treino entre os anos de 2004 e 2022: 228 registros\n",
            "Dados de Validação entre os anos de 2023 e 2023: 12 registros\n",
            "Dados de Teste entre os anos de 2024 e 2024: 4 registros\n"
          ]
        }
      ],
      "source": [
        "ano_inicio_teste = 2024\n",
        "ano_inicio_validacao = 2023  # Defina como None se não quiser validação\n",
        "\n",
        "if ano_inicio_validacao != None:\n",
        "    train_ds = dataset[dataset['ds'].dt.year < ano_inicio_validacao].copy()\n",
        "    val_ds = dataset[(dataset['ds'].dt.year >= ano_inicio_validacao) & (dataset['ds'].dt.year < ano_inicio_teste)].copy()\n",
        "    test_ds = dataset[dataset['ds'].dt.year == ano_inicio_teste].copy()\n",
        "else:\n",
        "    train_ds = dataset[dataset['ds'].dt.year < ano_inicio_teste].copy()\n",
        "    test_ds = dataset[dataset['ds'].dt.year == ano_inicio_teste].copy()\n",
        "    val_ds = None\n",
        "\n",
        "print(f\"Dados de Treino entre os anos de {train_ds['ds'].dt.year.min()} e {train_ds['ds'].dt.year.max()}: {len(train_ds)} registros\")\n",
        "print(f\"Dados de Validação entre os anos de {val_ds['ds'].dt.year.min() if val_ds is not None else 'N/A'} e {val_ds['ds'].dt.year.max() if val_ds is not None else 'N/A'}: {len(val_ds) if val_ds is not None else 0} registros\")\n",
        "print(f\"Dados de Teste entre os anos de {test_ds['ds'].dt.year.min()} e {test_ds['ds'].dt.year.max()}: {len(test_ds)} registros\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVgNtXjOb4Q9"
      },
      "source": [
        "# Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tREOe8Mb9C1"
      },
      "source": [
        "## Normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8BDk6_7b5AB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Real: 60, Previsto: 60, Diferença: 0.0% \n",
            "Real: 71, Previsto: 71, Diferença: 0.0% \n",
            "Real: 58, Previsto: 55, Diferença: 5.17% \n",
            "Real: 52, Previsto: 51, Diferença: 1.92% \n",
            "Real: 50, Previsto: 49, Diferença: 2.0% \n",
            "Real: 50, Previsto: 47, Diferença: 6.0% \n",
            "Real: 49, Previsto: 47, Diferença: 4.08% \n",
            "Real: 48, Previsto: 46, Diferença: 4.17% \n",
            "Real: 48, Previsto: 47, Diferença: 2.08% \n",
            "Real: 57, Previsto: 55, Diferença: 3.51% \n",
            "Real: 68, Previsto: 66, Diferença: 2.94% \n",
            "Real: 90, Previsto: 89, Diferença: 1.11% \n",
            "\n",
            "\n",
            "Metricas com dados de Validação:\n",
            "WMAPE: 2.57%\n",
            "R²: 0.9782\n",
            "RMSE: 1.7795\n"
          ]
        }
      ],
      "source": [
        "# Teste do modelo base (dataset de chocolate)\n",
        "h = 12\n",
        "input_size = 48\n",
        "max_steps = 1000\n",
        "weight_decay = 1e-2\n",
        "default_params = {\n",
        "  'batch_size': 32,\n",
        "  'scaler_type': 'revin',\n",
        "  'encoder_dropout': 0.2,\n",
        "  'encoder_n_layers': 8,\n",
        "  'encoder_hidden_size': 128,\n",
        "  'decoder_layers': 2,\n",
        "  'decoder_hidden_size': 128,\n",
        "  'futr_exog_list': exog_list,\n",
        "  'learning_rate': 0.002388703885848156,\n",
        "  'max_steps': max_steps,\n",
        "  'loss': HuberLoss(delta=1.0),\n",
        "  'lr_scheduler': CyclicLR,\n",
        "  'lr_scheduler_kwargs': {\n",
        "      'base_lr': 1e-4,\n",
        "      'max_lr': 1e-2,\n",
        "      'step_size_up': int(max_steps * 0.45),\n",
        "      'mode': 'triangular',\n",
        "      'cycle_momentum': False\n",
        "  }\n",
        "}\n",
        "\n",
        "model_output = f\"model_based_{max_steps}\"\n",
        "train_model(\n",
        "    train_df=train_ds,\n",
        "    test_df=val_ds,\n",
        "    exog_list=exog_list,\n",
        "    h=h,\n",
        "    input_size=input_size,\n",
        "    default_params=default_params,\n",
        "    output_dir=f'./{model_output}'\n",
        ")\n",
        "\n",
        "model_output = \"model_1000\"  # Nome do diretório onde o modelo foi salvo\n",
        "model = NeuralForecast.load(path=model_output)\n",
        "\n",
        "futr_df = val_ds.drop(columns=[\"y\"]).copy()\n",
        "history_df = dataset[dataset['ds'] < futr_df['ds'].min()].copy()  # Dados históricos até o início do teste\n",
        "# Realiza a predição para a janela atual\n",
        "forecasts_df = model.predict(\n",
        "df=history_df,         # Dados históricos (para contexto)\n",
        "futr_df=futr_df      # Valores futuros das variáveis exógenas\n",
        ")\n",
        "\n",
        "evaluation_df = forecasts_df.merge(\n",
        "    val_ds[[\"unique_id\", \"ds\", \"y\"]],\n",
        "    on=[\"unique_id\", \"ds\"]\n",
        ")\n",
        "\n",
        "clear_output(wait=False)\n",
        "evaluation_df['LSTM'] = evaluation_df['LSTM'].round().astype(int)\n",
        "evaluation_df.rename(columns={'LSTM': 'y_pred'}, inplace=True)\n",
        "val_actual = evaluation_df['y']\n",
        "val_predicted = evaluation_df['y_pred']\n",
        "# Calcular o WMAPE (métrica a ser minimizada)\n",
        "val_score = wmape(val_actual, val_predicted)\n",
        "val_score = val_score * 100\n",
        "\n",
        "# Calcular R² usando sklearn\n",
        "val_r2 = r2_score(val_actual, val_predicted)\n",
        "\n",
        "# Calcular RMSE usando sklearn\n",
        "val_rmse = root_mean_squared_error(val_actual, val_predicted)\n",
        "\n",
        "for i in range(len(evaluation_df)):\n",
        "  print(f\"Real: {evaluation_df.iloc[i]['y']}, Previsto: {evaluation_df.iloc[i]['y_pred']}, Diferença: {calcula_diferenca_pct(evaluation_df.iloc[i])}% \")\n",
        "\n",
        "print(\"\\n\\nMetricas com dados de Validação:\")\n",
        "print(f\"WMAPE: {val_score:.2f}%\")\n",
        "print(f\"R²: {val_r2:.4f}\")\n",
        "print(f\"RMSE: {val_rmse:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61jln_mYb_UH"
      },
      "source": [
        "## Finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tabela de treinamentos:\n",
        "\n",
        "| Treino       | Validação | Teste |\n",
        "|--------------|-----------|-------|\n",
        "| 2012-2015    | 2016      | 2017  |\n",
        "| 2012-2016    | 2017      | 2018  |\n",
        "| 2012-2017    | 2018      | 2019  |\n",
        "| 2012-2018    | 2019      | 2020  |\n",
        "| 2012-2019    | 2020      | 2021  |\n",
        "| 2012-2020    | 2021      | 2022  |\n",
        "| 2012-2021    | 2022      | 2023  |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krt-mUIVy4GN"
      },
      "outputs": [],
      "source": [
        "local = \"predicao_2019\"\n",
        "\n",
        "h= 1\n",
        "input_size = 3\n",
        "steps_options = generate_steps_options()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uZBJZCA3XCW"
      },
      "outputs": [],
      "source": [
        "if len(exog_list) != 0:\n",
        "    # Diretório onde o modelo e o CSV de métricas serão salvos\n",
        "    shutil.rmtree(\"./Logs\")\n",
        "    base_dir = Path(f\"./Modelos/{local}\")\n",
        "    log_dir = Path(f\"./Logs\")\n",
        "    base_dir.mkdir(parents=True, exist_ok=True)\n",
        "    log_dir.mkdir(parents=True, exist_ok=True)\n",
        "    best_score_global = float(\"inf\")\n",
        "\n",
        "    def objective(trial):\n",
        "        global best_score_global\n",
        "\n",
        "        # 1) Hiperparâmetros a serem otimizados\n",
        "        encoder_n_layers = trial.suggest_int(\"encoder_n_layers\", 3, 8)\n",
        "        encoder_hidden_size = trial.suggest_categorical(\"encoder_hidden_size\", [64, 128, 192, 256])\n",
        "        decoder_layers = trial.suggest_int(\"decoder_layers\", 1, 4)\n",
        "        decoder_hidden_size = trial.suggest_categorical(\"decoder_hidden_size\", [64, 128, 192, 256])\n",
        "        learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
        "        #weight_decay = trial.suggest_categorical(\"weight_decay\", [1e-5, 1e-4, 1e-2]) # weight_decay (L2 regularization)\n",
        "        #dropout = trial.suggest_categorical(\"dropout\", [0.2, 0.3, 0.4, 0.5]) # dropout rate\n",
        "        #batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64]) # tem poucos dados, não precisa de batch grande\n",
        "        #steps = trial.suggest_categorical(\"steps\", steps_options)\n",
        "        \n",
        "        # Parametros fixos\n",
        "        batch_size = 32  # Mantido fixo\n",
        "        dropout = 0.2  # Mantido fixo\n",
        "        #weight_decay = 1e-2  #V1\n",
        "        #weight_decay = 5e-2   # 5 vezes mais forte V2\n",
        "        #weight_decay = 1e-1   # 10 vezes mais forte V3\n",
        "        #weight_decay = 2e-1   # 20 vezes mais forte V4\n",
        "        #weight_decay = 5e-1   # 50 vezes mais forte V5\n",
        "        #weight_decay = 1.0    # 100 vezes mais forte V6\n",
        "        weight_decay = 1e-4  # Mantido fixo V7\n",
        "        #weight_decay = 1e-5 #V8\n",
        "        steps = 1000\n",
        "\n",
        "        # 2) Configuração do CSVLogger\n",
        "        csv_logger = CSVLogger(\n",
        "            save_dir=\"./Logs\",  # \"./Modelos/previsoes_2023_V8\"\n",
        "            name=\"logs\"              # → \"./Modelos/previsoes_2023_V8/logs/version_<n>\"\n",
        "        )\n",
        "\n",
        "        # 4) Instanciação do modelo LSTM (passando o CSVLogger)\n",
        "        model = LSTM(\n",
        "            h=h,\n",
        "            input_size=input_size,\n",
        "            batch_size=batch_size,\n",
        "            scaler_type=\"revin\",\n",
        "            encoder_dropout=dropout,\n",
        "            encoder_n_layers=encoder_n_layers,\n",
        "            encoder_hidden_size=encoder_hidden_size,\n",
        "            decoder_layers=decoder_layers,\n",
        "            decoder_hidden_size=decoder_hidden_size,\n",
        "            futr_exog_list=exog_list,\n",
        "            learning_rate=learning_rate,\n",
        "            max_steps=steps,\n",
        "            loss= HuberLoss(delta=1.0),        \n",
        "            optimizer=AdamW,                                       \n",
        "            optimizer_kwargs={\"weight_decay\": weight_decay}, \n",
        "            lr_scheduler=CyclicLR,\n",
        "            lr_scheduler_kwargs={\n",
        "                \"base_lr\": 1e-4,\n",
        "                \"max_lr\": 1e-2,\n",
        "                \"step_size_up\": int(steps * 0.45),\n",
        "                \"mode\": \"triangular\",\n",
        "                \"cycle_momentum\": False\n",
        "            },\n",
        "            logger=csv_logger\n",
        "        )\n",
        "\n",
        "        # 5) Cria o NeuralForecast\n",
        "        nf = NeuralForecast(models=[model], freq=\"YE\") # YE = Year End\n",
        "\n",
        "        # 6) Executa o fit\n",
        "        nf.fit(df=train_ds)\n",
        "\n",
        "        # 7) Avaliação “rolling” após o treino\n",
        "        combined_df = rolling_evaluation(\n",
        "            model=nf,\n",
        "            full_df=dataset,\n",
        "            test_df=val_ds if val_ds is not None else test_ds, # Usa val_ds se existir, caso contrário usa test_ds\n",
        "            context_size=input_size,\n",
        "            horizon=h,\n",
        "            inteiro=False\n",
        "        )\n",
        "        clear_output(wait=False)\n",
        "\n",
        "        # 8) Cálculo da métrica (RMSE)\n",
        "        actual = combined_df[\"y\"]\n",
        "        predicted = combined_df[\"LSTM\"]\n",
        "        score = root_mean_squared_error(actual, predicted)\n",
        "\n",
        "        #time.sleep(30)  # Pausa para evitar problemas de concorrência com o Optuna\n",
        "        if score < best_score_global:\n",
        "            best_score_global = score\n",
        "\n",
        "            # 10.1) Salvar o modelo\n",
        "            nf.save(\n",
        "                path=str(base_dir),\n",
        "                model_index=None,\n",
        "                overwrite=True,\n",
        "                save_dataset=True\n",
        "            )\n",
        "\n",
        "            # 10.2) Salvar as previsões em Excel\n",
        "            combined_df.to_excel(f\"{base_dir}/valores_predicao.xlsx\", index=False)\n",
        "\n",
        "            version_folders = sorted(glob.glob(str(log_dir / \"logs\" / \"version_*\")))\n",
        "            shutil.copy(f\"{version_folders[-1]}/metrics.csv\", f\"{base_dir}/metrics.csv\")\n",
        "            shutil.copy(f\"{version_folders[-1]}/hparams.yaml\", f\"{base_dir}/hparams.yaml\")\n",
        "        return score\n",
        "else:\n",
        "    print(\"Não há variáveis exógenas para treinar o modelo!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lista de configurações iniciais (cada dicionário é um conjunto de parâmetros)\n",
        "trials_iniciais = [\n",
        "    { # melhor para V0\n",
        "        'encoder_n_layers': 3,\n",
        "        'encoder_hidden_size': 128,\n",
        "        'decoder_layers': 4,\n",
        "        'decoder_hidden_size': 192,\n",
        "        'learning_rate': 0.007928638381888188\n",
        "    },\n",
        "    { # melhor para V6\n",
        "        'encoder_n_layers': 5,\n",
        "        'encoder_hidden_size': 192,\n",
        "        'decoder_layers': 4,\n",
        "        'decoder_hidden_size': 192,\n",
        "        'learning_rate': 0.0020963876959934655\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHhalzR40Idl"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Criar estudo Optuna\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "\n",
        "# Enfileirar trials iniciais para serem avaliados primeiro\n",
        "for params in trials_iniciais:\n",
        "    study.enqueue_trial(params)\n",
        "\n",
        "# Executar otimização (n_trials pode incluir os trials enfileirados)\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "# Exibir resultados\n",
        "print(\"Melhor trial:\")\n",
        "best = study.best_trial\n",
        "print(f\"  RMSE: {best.value}\")\n",
        "print(\"  Parâmetros:\")\n",
        "for key, value in best.params.items():\n",
        "    print(f\"    {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_losses(f\"{base_dir}/metrics.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR8DP-EncCX9"
      },
      "source": [
        "# Predições"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQpHcDaecF1V"
      },
      "source": [
        "O dataframe com as predições deve ter:\n",
        "* treino_id: um id que permite diferenciar o treino.\n",
        "* Unique_Id: O identificador de cada serie.\n",
        "* ds: a data de cada registro.\n",
        "* y: o valor real do registro para a data e a serie.\n",
        "* y_pred: o valor predito pelo modelo, caso não tenha deve preencher com NaN.\n",
        "* flag: indica se o registro foi usado no treino ou teste.\n",
        "* dataset: o nome do dataset usado para treinar e avaliar o modelo.\n",
        "* modelo: nome do algoritmo do modelo (LSTM, Randon Florest).\n",
        "* comentario: alguma anotação que pode ser util (pode ser vazio)\n",
        "* data do teino: data que o modelo foi treinado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(\"./Logs/logs/version_66\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8l9C8S6vRmW"
      },
      "outputs": [],
      "source": [
        "# carregue o modelo\n",
        "path = \"Modelos/predicao_2019\"\n",
        "print(f\"Diretório do modelo: {path}\")\n",
        "\n",
        "model = NeuralForecast.load(path=path)\n",
        "input_size = 4\n",
        "h = 1\n",
        "predictions = rolling_evaluation(\n",
        "    model=model,\n",
        "    full_df=dataset,\n",
        "    test_df=test_ds,\n",
        "    context_size=input_size,\n",
        "    horizon=h\n",
        ")\n",
        "clear_output()\n",
        "\n",
        "actual = predictions['y']\n",
        "predicted = predictions['LSTM']\n",
        "# Calcular o WMAPE (métrica a ser minimizada)\n",
        "score = wmape(actual, predicted)\n",
        "score = score * 100\n",
        "\n",
        "# Calcular R² usando sklearn\n",
        "r2 = r2_score(actual, predicted)\n",
        "\n",
        "# Calcular RMSE usando sklearn\n",
        "rmse = root_mean_squared_error(actual, predicted)\n",
        "\n",
        "print(\"Metricas com dados de Teste:\")\n",
        "print(f\"WMAPE: {score:.2f}%\")\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f} Toneladas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testa o desempenho do modelo com os dados de validação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_predictions = rolling_evaluation(\n",
        "    model=model,\n",
        "    full_df=dataset,\n",
        "    test_df=val_ds,\n",
        "    context_size=input_size,\n",
        "    horizon=h\n",
        ")\n",
        "clear_output()\n",
        "\n",
        "val_actual = val_predictions['y']\n",
        "val_predicted = val_predictions['LSTM']\n",
        "# Calcular o WMAPE (métrica a ser minimizada)\n",
        "val_score = wmape(val_actual, val_predicted)\n",
        "val_score = val_score * 100\n",
        "\n",
        "# Calcular R² usando sklearn\n",
        "val_r2 = r2_score(val_actual, val_predicted)\n",
        "\n",
        "# Calcular RMSE usando sklearn\n",
        "val_rmse = root_mean_squared_error(val_actual, val_predicted)\n",
        "\n",
        "print(\"Metricas com dados de Validação:\")\n",
        "print(f\"WMAPE: {val_score:.2f}%\")\n",
        "print(f\"R²: {val_r2:.4f}\")\n",
        "print(f\"RMSE: {val_rmse:.4f} Toneladas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testa o desempenho do modelo com os dados de treino. (a partir do periodo em que tiver contexto suficiente)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "insample_df = model.predict_insample(step_size=h)\n",
        "\n",
        "# Inversão da transformação log1p\n",
        "insample_df['y'] = np.expm1(insample_df['y'])\n",
        "insample_df['LSTM'] = np.expm1(insample_df['LSTM'])\n",
        "\n",
        "# Filtrar para garantir contexto suficiente\n",
        "contexto = 3 # tamanho da janela de contexto\n",
        "min_cutoff_valido = pd.to_datetime(insample_df['cutoff'].min()) + pd.DateOffset(years=contexto)\n",
        "insample_df = insample_df[insample_df['cutoff'] >= min_cutoff_valido].copy()\n",
        "\n",
        "# Arredondar os valores para inteiros\n",
        "insample_df['y'] = insample_df['y'].round()\n",
        "insample_df['LSTM'] = insample_df['LSTM'].round()\n",
        "\n",
        "clear_output()\n",
        "\n",
        "train_actual = insample_df['y']\n",
        "train_predicted = insample_df['LSTM']\n",
        "# Calcular o WMAPE (métrica a ser minimizada)\n",
        "train_score = wmape(train_actual, train_predicted)\n",
        "train_score = train_score * 100\n",
        "\n",
        "# Calcular R² usando sklearn\n",
        "train_r2 = r2_score(train_actual, train_predicted)\n",
        "\n",
        "# Calcular RMSE usando sklearn\n",
        "train_rmse = root_mean_squared_error(train_actual, train_predicted)\n",
        "\n",
        "print(\"Metricas com dados de Treino:\")\n",
        "print(f\"WMAPE: {train_score:.2f}%\")\n",
        "print(f\"R²: {train_r2:.4f}\")\n",
        "print(f\"RMSE: {train_rmse:.2f} Toneladas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfyysTeSJRPr"
      },
      "source": [
        "Salva os resultados do treino."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGzq_yKgpEQY"
      },
      "outputs": [],
      "source": [
        "colunas = [\n",
        "  'treino_id',    # Identificador do treino\n",
        "  'unique_id',    # Identificador de cada série\n",
        "  'ds',           # Data de cada registro\n",
        "  'y',            # Valor real\n",
        "  'y_pred',       # Valor predito pelo modelo\n",
        "  'diferença_%',  # Valor da diferença percentual entre o valor predito e o real\n",
        "  'flag',         # Indica se foi usado em treino, validação ou teste\n",
        "  'dataset',      # Nome do dataset usado\n",
        "  'modelo',       # Nome do algoritmo (LSTM, Random Forest, etc)\n",
        "  'comentario',   # Anotações adicionais (pode ser vazio)\n",
        "  'data_treino'   # Data que o modelo foi treinado\n",
        "]\n",
        "\n",
        "# Verificar existência do arquivo\n",
        "arquivo_predicoes = 'predicoes_modelos.csv'\n",
        "\n",
        "if not os.path.exists(arquivo_predicoes):\n",
        "  # Criar DataFrame vazio com as colunas especificadas\n",
        "  df = pd.DataFrame(columns=colunas)\n",
        "\n",
        "  # Salvar o DataFrame vazio como CSV\n",
        "  df.to_csv(arquivo_predicoes, index=False)\n",
        "  print(f\"Arquivo {arquivo_predicoes} criado com DataFrame vazio.\")\n",
        "else:\n",
        "  df = pd.read_csv(arquivo_predicoes)\n",
        "  df['ds'] = (pd.to_datetime(df['ds'], errors='coerce').fillna(pd.Timestamp.now()).dt.strftime('%Y-%m-%dT%H:%M:%S'))\n",
        "  print(f\"Arquivo {arquivo_predicoes} já existe. Nenhuma ação necessária.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8jtTG7vv2J7"
      },
      "source": [
        "Prepara os dados do teste com os valore da predição."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJ5CiL9uqkYu"
      },
      "outputs": [],
      "source": [
        "dados_teste = predictions[['unique_id', 'ds', 'y', 'LSTM', 'diferença_%']].copy()\n",
        "dados_teste.columns = ['unique_id', 'ds', 'y', 'y_pred', 'diferença_%'] # Renomeando as colunas para o formato esperado\n",
        "dados_teste['flag'] = 'teste'\n",
        "dados_teste['ds'] = pd.to_datetime(dados_teste['ds']).fillna(dados_teste['ds'])\n",
        "dados_teste['ds'] = (pd.to_datetime(dados_teste['ds'], errors='coerce').fillna(pd.Timestamp.now()).dt.strftime('%Y-%m-%dT%H:%M:%S'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepara os dados de validação com as colunas necessárias\n",
        "if val_ds is not None:\n",
        "    dados_validacao = rolling_evaluation(\n",
        "        model=model,\n",
        "        full_df=dataset,\n",
        "        test_df=val_ds,\n",
        "        context_size=input_size,\n",
        "        horizon=h\n",
        "    )\n",
        "    dados_validacao = dados_validacao[['unique_id', 'ds', 'y', 'LSTM', 'diferença_%']].copy()\n",
        "    dados_validacao.columns = ['unique_id', 'ds', 'y', 'y_pred', 'diferença_%'] # Renomeando as colunas para o formato esperado\n",
        "    dados_validacao['flag'] = 'validacao'\n",
        "    dados_validacao['ds'] = pd.to_datetime(dados_validacao['ds']).fillna(dados_validacao['ds'])\n",
        "    dados_validacao['ds'] = (pd.to_datetime(dados_validacao['ds'], errors='coerce').fillna(pd.Timestamp.now()).dt.strftime('%Y-%m-%dT%H:%M:%S'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDpVIIVgwSWT"
      },
      "source": [
        "Prepara os dados do treino, servirão como dados historicos para fazer os graficos posteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_treino = dataset[['unique_id', 'ds', 'y']].copy()\n",
        "dados_treino['y'] = round(np.expm1(dados_treino['y']),2)\n",
        "\n",
        "if val_ds is not None:\n",
        "    inicio_teste = val_ds['ds'].min()\n",
        "    print(f\"Periodo de inicio da Validação: {inicio_teste}\\n\")\n",
        "else:\n",
        "    inicio_teste = dados_teste['ds'].min() # identifica o periodo de inicio dos teste\n",
        "    print(f\"Periodo de inicio dos Testes: {inicio_teste}\\n\")\n",
        "dados_treino = dados_treino[dados_treino['ds'] < inicio_teste] # pega apenas as datas anteriores ao periodo de teste\n",
        "dados_treino['y_pred'] = \"-\"  # \"- \" para previsões no treino, nesse ponto elas não exitem.\n",
        "\n",
        "insample_preds = insample_df[['unique_id', 'ds', 'LSTM']].copy()\n",
        "insample_preds = insample_preds.rename(columns={'LSTM': 'y_pred_temp'})\n",
        "# Faz o merge dos dados de treino com as previsões disponíveis no insample_df\n",
        "dados_treino = dados_treino.merge(insample_preds, on=['unique_id', 'ds'], how='left')\n",
        "# Atualiza a coluna y_pred: onde tiver previsão do insample_df usa ela, senão mantém o \"-\"\n",
        "dados_treino['y_pred'] = dados_treino['y_pred_temp'].combine_first(dados_treino['y_pred'])\n",
        "# Remove a coluna temporária\n",
        "dados_treino = dados_treino.drop(columns=['y_pred_temp'])\n",
        "\n",
        "dados_treino['diferença_%'] = \"-\"  # \"-\" para a diferença percentual entre predito e real, nesse ponto elas não exitem.\n",
        "dados_treino['flag'] = 'treino'\n",
        "dados_treino['ds'] = (pd.to_datetime(dados_treino['ds'], errors='coerce').fillna(pd.Timestamp.now()).dt.strftime('%Y-%m-%dT%H:%M:%S'))\n",
        "\n",
        "dados_treino['diferença_%'] = dados_treino.apply(calcula_diferenca_pct, axis=1)\n",
        "dados_treino['flag'] = 'treino'\n",
        "dados_treino['ds'] = (pd.to_datetime(dados_treino['ds'], errors='coerce').fillna(pd.Timestamp.now()).dt.strftime('%Y-%m-%dT%H:%M:%S'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsjze17cyIby"
      },
      "source": [
        "Combina os dois dataframes em um unico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if val_ds is not None:\n",
        "    # Concatena os dados de treino, validação e teste\n",
        "    dados_completos = pd.concat([dados_treino, dados_validacao, dados_teste], ignore_index=True)\n",
        "else:\n",
        "    # Concatena apenas os dados de treino e teste\n",
        "    dados_completos = pd.concat([dados_treino, dados_teste], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETi5IBLMCsHR"
      },
      "source": [
        "Adiciona as informações sobre o treino atual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAamYUMxDIF2"
      },
      "outputs": [],
      "source": [
        "dados_completos['treino_id'] = \"Predicao_2019\"  # Identificador do treino\n",
        "dados_completos['dataset'] = \"V15\"  # Nome do dataset usado\n",
        "dados_completos['modelo'] = \"LSTM\"\n",
        "dados_completos['data_treino'] = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tabela de treinamentos:\n",
        "\n",
        "| Treino       | Validação | Teste |\n",
        "|--------------|-----------|-------|\n",
        "| 2012-2015    | 2016      | 2017  |\n",
        "| 2012-2016    | 2017      | 2018  |\n",
        "| 2012-2017    | 2018      | 2019  |\n",
        "| 2012-2018    | 2019      | 2020  |\n",
        "| 2012-2019    | 2020      | 2021  |\n",
        "| 2012-2020    | 2021      | 2022  |\n",
        "| 2012-2021    | 2022      | 2023  |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_completos['comentario'] = \"\"\"\n",
        "O objetivo deste teste foi avaliar a performance do modelo LSTM em diferentes anos de safra.\n",
        "Distribuição dos dados:\n",
        "| Treino       | Validação | Teste |\n",
        "|--------------|-----------|-------|\n",
        "| 2012-2015    | 2016      | 2017  |\n",
        "| 2012-2016    | 2017      | 2018  |\n",
        "| 2012-2017    | 2018      | 2019  |\n",
        "| 2012-2018    | 2019      | 2020  |\n",
        "| 2012-2019    | 2020      | 2021  |\n",
        "| 2012-2020    | 2021      | 2022  |\n",
        "| 2012-2021    | 2022      | 2023  |\n",
        "\n",
        "Para o ajuste de hiperparâmetros foi utilizado o Optuna, com 20 iterações.\n",
        "Para regularização foi utilizado dropout de 0.2 e weight_decay de 1e-4.\n",
        "As previsões foram feitas com o modelo LSTM, utilizando variáveis exógenas:\n",
        "Usando one-hot encoding para o nome dos municípios e mesorregiões.\n",
        "Para os dados climáticos foram utilizados os valores brutos mensais de precipitação, temperatura mínima e máxima.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados_completos['comentario'] = \"\"\"\n",
        "O objetivo deste teste foi avaliar o impacto do uso das variaveis exogenas na performance do modelo LSTM.\n",
        "weight_decay = 1e-4\n",
        "Modelo treinado com dados entre 2012-2021, validado com dados de 2022 e testado com dados de 2023.\n",
        "Para o ajuste de hiperparâmetros foi utilizado o Optuna, com 70 iterações.\n",
        "Para regularização foi utilizado dropout de 0.2.\n",
        "As previsões foram feitas com o modelo LSTM, utilizando variáveis exógenas:\n",
        "Usando one-hot encoding para o nome dos municípios e mesorregiões.\n",
        "Para os dados climáticos foram utilizados os valores brutos mensais de precipitação, temperatura mínima e máxima.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhQX-bZwCoe5"
      },
      "outputs": [],
      "source": [
        "dados_completos['comentario'] = \"\"\"\n",
        "O objetivo deste teste foi avaliar o impacto do weight decay na performance do modelo LSTM.\n",
        "Versões:\n",
        "   V0: sem o uso do weight decay\n",
        "   V1: weight_decay = 1e-2\n",
        "   V2: weight_decay = 5e-2   # 5 vezes mais forte\n",
        "   V3: weight_decay = 1e-1   # 10 vezes mais forte\n",
        "   V4: weight_decay = 2e-1   # 20 vezes mais forte\n",
        "   V5: weight_decay = 5e-1   # 50 vezes mais forte\n",
        "   V6: weight_decay = 1.0    # 100 vezes mais forte\n",
        "   V7: weight_decay = 1e-4 \n",
        "   V8: weight_decay = 1e-5 \n",
        "\n",
        "Modelo treinado com dados entre 2012-2021, validado com dados de 2022 e testado com dados de 2023.\n",
        "Para o ajuste de hiperparâmetros foi utilizado o Optuna, com 70 iterações.\n",
        "Para regularização foi utilizado dropout de 0.5.\n",
        "As previsões foram feitas com o modelo LSTM, utilizando variáveis exógenas:\n",
        "Usando one-hot encoding para o nome dos municípios e mesorregiões.\n",
        "Para os dados climáticos foram utilizados os valores brutos mensais de precipitação, temperatura mínima e máxima.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdWVo8iXDXR-"
      },
      "source": [
        "Junta os dados do treino atual com os anteriores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1ZaC1aCJbfq"
      },
      "outputs": [],
      "source": [
        "nova_ordem_colunas = ['treino_id', 'unique_id', 'ds', 'y', 'y_pred', 'diferença_%', 'flag', 'dataset', 'modelo', 'comentario', 'data_treino']\n",
        "\n",
        "# Reordenar as colunas\n",
        "dados_completos = dados_completos[nova_ordem_colunas]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfXMFTBODVfQ"
      },
      "outputs": [],
      "source": [
        "df_final = pd.concat([df, dados_completos], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPDF_q5kP_Hn"
      },
      "outputs": [],
      "source": [
        "print(f\"Treinamentos realizados:\")\n",
        "for treino in df_final['treino_id'].unique():\n",
        "  print(f\" - {treino} ({df_final[df_final['treino_id']==treino]['data_treino'].unique()[0]})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final.to_csv(arquivo_predicoes, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Ao final troque o id do municipio pelo nome dele**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(\"predicoes_modelos_municipio.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMpkcgV1F5dUb+UUoEWC2tY",
      "collapsed_sections": [
        "7FXKQua4bjZ-",
        "7tREOe8Mb9C1"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Educampo",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
